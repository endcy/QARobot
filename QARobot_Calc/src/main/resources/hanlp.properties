#配置根路径，Windows路径分隔符统一使用/
root=D:/NLP/HanLP_Single
#词向量模型路径
#defVecModelPath=D:/NLP/vector/wechar-article-352196-256.txt
defVecModelPath=D:/NLP/vector/baidu-baike-635974-300.txt
#defVecModelPath=D:/NLP/vector/sougou-test-52479-200.txt
#文档向量分词采用的分词器类型----维特比(viterbi)：效率和效果的最佳平衡;双数组trie树 (dat)：极速词典分词;条件随机场 (crf)：分词、词性标注与命名实体识别精度都较高，适合要求较高的NLP任务;
# 感知机 (perceptron)：分词、词性标注与命名实体识别，支持在线学习;N最短路 (nshort)：命名实体识别稍微好一些，牺牲了速度
docModelSegmentType=viterbi
#是否初始化数据库中的QA-Q到文档向量
isInitModel4DB=0
#是否打印文档向量分词过程
isPrintSegWords=1
#自定义领域同义词路径
CustomSynonymDic2VecPath=data/dictionary/synonym/领域同义词.txt
#核心词典路径
CoreDictionaryPath=data/dictionary/CoreNatureDictionary.txt
#2元语法词典路径
BiGramDictionaryPath=data/dictionary/CoreNatureDictionary.ngram.txt
#核心词典路径
#CoreDictionaryPath=data/dictionary/CoreNatureDictionary.txt
#自定义词典路径，用;隔开多个自定义词典，空格开头表示在同一个目录，使用“文件名 词性”形式则表示这个词典的词性默认是该词性。优先级递减。
#所有词典统一使用UTF-8编码，每一行代表一个单词，格式遵从[单词] [词性A] [A的频次] [词性B] [B的频次] ... 如果不填词性则表示采用词典的默认词性。
CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; 现代汉语补充词库.txt; 全国地名大全.txt ns; 人名词典.txt; 机构名词典.txt; 保险词汇.txt; 上海地名.txt ns;data/dictionary/person/nrf.txt nrf;
#停用词词典路径
#CoreStopWordDictionaryPath=data/dictionary/stopwords.txt
#同义词词典路径
#CoreSynonymDictionaryDictionaryPath=data/dictionary/synonym/CoreSynonym.txt
#人名词典路径
#PersonDictionaryPath=data/dictionary/person/nr.txt
#繁简词典根目录
#tcDictionaryRoot=data/dictionary/tc
#HMM分词模型
#HMMSegmentModelPath=data/model/segment/HMMSegmentModel.bin
#分词结果是否展示词性
#ShowTermNature=true
#IO适配器，实现com.hankcs.hanlp.corpus.io.IIOAdapter接口以在不同的平台（Hadoop、Redis等）上运行HanLP
#默认的IO适配器如下，该适配器是基于普通文件系统的。
#IOAdapter=com.hankcs.hanlp.corpus.io.FileIOAdapter
